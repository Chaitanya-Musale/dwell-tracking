import tkinter as tk
from tkinter import filedialog, messagebox
import cv2
from ultralytics import YOLO
import pandas as pd
import numpy as np
import os
import subprocess
from tqdm import tqdm
import matplotlib.pyplot as plt
from IPython.display import Video, display

def verify_login(username, password):
    if username == 'admin' and password == 'abc':
        return True
    return False

def browse_video():
    global video_path
    video_path = filedialog.askopenfilename(filetypes=[("MP4 files", "*.mp4")])
    if video_path:
        video_path_label.config(text=f"Selected Video: {video_path}")
    else:
        video_path_label.config(text="No video selected.")

def resize_frame(frame, scale_percent=100):
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    resized = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)
    return resized

def filter_tracks(centers, patience):
    filter_dict = {}
    for k, v in centers.items():
        d_frames = list(v.items())[-patience:]
        filter_dict[k] = dict(d_frames)
    return filter_dict

def update_tracking(centers_old, obj_center, thr_centers, lastKey, frame, frame_max):
    is_new = 0
    lastpos = [(k, v) for k, v in centers_old.items() if abs(list(v.keys())[-1] - frame) <= frame_max]
    previous_pos = [k for k, centers in lastpos if (np.linalg.norm(np.array(list(centers.values())[-1]) - np.array(obj_center)) < thr_centers)]

    if previous_pos:
        id_obj = previous_pos[0]
        centers_old[id_obj][frame] = obj_center
    else:
        lastKey += 1
        id_obj = lastKey
        centers_old[id_obj] = {frame: obj_center}
        is_new = 1
    return centers_old, is_new, lastKey

class FPSBasedTimer:
    def __init__(self, fps=30):
        self.fps = fps
        self.frame_id = 0
        self.tracker_id2frame_id = {}

    def tick(self, tracker_ids):
        self.frame_id += 1
        times = {}
        for tracker_id in tracker_ids:
            if tracker_id not in self.tracker_id2frame_id:
                self.tracker_id2frame_id[tracker_id] = self.frame_id
            times[tracker_id] = (self.frame_id - self.tracker_id2frame_id[tracker_id]) / self.fps
        return times

def start_processing():
    if not video_path:
        messagebox.showerror("Error", "Please select a video file first!")
        return
    main(video_path)

def main(video_path):
    model = YOLO('yolov8x.pt')  # Load the YOLO model
    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    output_path = "output.mp4"
    tmp_output_path = "tmp_output.avi"
    output_video = cv2.VideoWriter(tmp_output_path, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))

    timer = FPSBasedTimer(fps)
    centers_old = {}
    count_p = 0 
    lastKey = 0  

    for i in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), desc="Processing Video"):
        ret, frame = cap.read()
        if not ret:
            print(f"[WARNING] - Skipping frame {i} due to read error")
            continue

        frame = resize_frame(frame, 100)
        ROI = frame[390:800, 700:1300]

        y_hat = model.predict(ROI, conf=0.8, classes=[0], device='cpu', verbose=False)
        boxes = y_hat[0].boxes.xyxy.cpu().numpy()
        conf = y_hat[0].boxes.conf.cpu().numpy()
        classes = y_hat[0].boxes.cls.cpu().numpy()

        positions_frame = pd.DataFrame(np.hstack((boxes, conf[:, np.newaxis], classes[:, np.newaxis])), columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class'])
        labels = [model.model.names[int(cls)] for cls in classes]

        tracker_ids = []
        for index, row in positions_frame.iterrows():
            xmin, ymin, xmax, ymax, confidence, category = row[:6].astype(int)
            center_x, center_y = (xmin + xmax) // 2, (ymin + ymax) // 2
            centers_old, is_new, lastKey = update_tracking(centers_old, (center_x, center_y), 20, lastKey, i, 5)
            count_p += is_new
            tracker_ids.append(lastKey)

            cv2.rectangle(ROI, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)
            for center_x, center_y in centers_old[lastKey].values():
                cv2.circle(ROI, (center_x, center_y), 5, (0, 0, 255), -1)

        cv2.putText(frame, f'Counts People in ROI: {count_p}', (30, 40), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (255, 0, 0), 1)
        output_video.write(frame)

        dwell_times = timer.tick(tracker_ids)
        print(f"Frame {i}: Dwell times for objects in ROI: {dwell_times}")

    output_video.release()
    cap.release()
    cv2.destroyAllWindows()

    if os.path.exists(output_path):
        os.remove(output_path)
    subprocess.run(["ffmpeg", "-i", tmp_output_path, "-crf", "18", "-preset", "veryfast", "-hide_banner", "-loglevel", "error", "-vcodec", "libx264", output_path])
    os.remove(tmp_output_path)

app = tk.Tk()
app.title("Video Processing Application")

login_frame = tk.Frame(app)
login_frame.pack(pady=20)

tk.Label(login_frame, text="Username:").grid(row=0, column=0)
username_entry = tk.Entry(login_frame)
username_entry.grid(row=0, column=1)

tk.Label(login_frame, text="Password:").grid(row=1, column=0)
password_entry = tk.Entry(login_frame, show="*")
password_entry.grid(row=1, column=1)

def login():
    user = username_entry.get()
    pwd = password_entry.get()
    if verify_login(user, pwd):
        video_frame.pack(pady=20)
    else:
        messagebox.showerror("Login Failed", "Incorrect username or password")

login_button = tk.Button(login_frame, text="Login", command=login)
login_button.grid(row=2, columnspan=2)

video_frame = tk.Frame(app)
video_path_label = tk.Label(video_frame, text="No video selected.")
video_path_label.pack()

browse_button = tk.Button(video_frame, text="Browse Video", command=browse_video)
browse_button.pack()

process_button = tk.Button(video_frame, text="Start Processing", command=start_processing)
process_button.pack()

app.mainloop()
